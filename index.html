<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="scroll-restoration" content="manual">
    <title>HalluHard - Hallucination Benchmark Leaderboard</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Source+Sans+3:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header>
            <h1>HalluHard</h1>
            <p class="subtitle">Hallucination Benchmark Leaderboard</p>
            <!-- <p class="description">
                A comprehensive benchmark evaluating hallucination rates across multiple domains and conversation turns.
                Lower hallucination rates indicate better performance.
            </p> -->
            <nav class="main-nav">
                <a href="index.html" class="nav-link active">Overview</a>
                <a href="legal_cases.html" class="nav-link">Legal Cases</a>
                <a href="research_questions.html" class="nav-link">Research Questions</a>
                <a href="medical_guidelines.html" class="nav-link">Medical Guidelines</a>
                <a href="coding.html" class="nav-link">Coding</a>
            </nav>
        </header>

        <div class="controls">
            <div class="control-group">
                <label for="domain-select">Domain:</label>
                <select id="domain-select">
                    <option value="all" selected>All Domains (Average)</option>
                    <option value="legal_cases">Legal Cases</option>
                    <option value="research_questions">Research Questions</option>
                    <option value="medical_guidelines">Medical Guidelines</option>
                    <option value="coding">Coding</option>
                </select>
            </div>
            <div class="control-group">
                <label for="turn-select">Turn:</label>
                <select id="turn-select">
                    <option value="avg" selected>Average</option>
                    <option value="1">Turn 1</option>
                    <option value="3">Turn 3</option>
                    <option value="5">Turn 5</option>
                </select>
            </div>
        </div>

        <div class="leaderboard-container">
            <div id="chart-view">
                <div class="chart-container">
                    <svg id="bar-chart" width="100%" height="600"></svg>
                </div>
            </div>
            <div id="table-view">
                <table class="leaderboard" id="leaderboard">
                    <thead>
                        <tr>
                            <th class="rank-col sortable" data-sort="rank">Rank <span class="sort-icon">â†•</span></th>
                            <th class="model-col sortable" data-sort="name">Model <span class="sort-icon">â†•</span></th>
                            <th class="rate-col sortable active-sort" data-sort="rate">Hallucination Rate <span class="sort-icon">â†‘</span></th>
                            <th class="domain-breakdown-col" id="domain-breakdown-header" style="display: none;">
                                <div>Domain Breakdown</div>
                                <div class="domain-labels">
                                    <span class="domain-sortable" data-sort="legal_cases">Legal <span class="sort-icon">â†•</span></span>
                                    <span class="domain-sortable" data-sort="research_questions">Research <span class="sort-icon">â†•</span></span>
                                    <span class="domain-sortable" data-sort="medical_guidelines">Medical <span class="sort-icon">â†•</span></span>
                                    <span class="domain-sortable" data-sort="coding">Coding <span class="sort-icon">â†•</span></span>
                                </div>
                            </th>
                        </tr>
                    </thead>
                    <tbody id="leaderboard-body">
                        <tr>
                            <td colspan="4" class="loading">Loading data...</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </div>

        <div class="insights-section">
            <h2>Key Takeaways</h2>
            <div class="insights-grid-vertical">
                <div class="insight-card">
                    <h3><span class="takeaway-number">1</span> Turn Progression and Self-Conditioning</h3>
                    <p>Models hallucinate more in later turns for citation-grounded tasks because they condition on their own earlier mistakes (3-20% of incorrect references reappear), though coding shows a downward trend as tasks narrow from broad to focused.</p>
                </div>
                <div class="insight-card">
                    <h3><span class="takeaway-number">2</span> Model Capability Matters</h3>
                    <p>More capable models consistently demonstrate lower hallucination rates, with larger models (GPT-5-nano â†’ GPT-5-mini â†’ GPT-5) and newer flagship models (GPT-5.2, Claude-Opus) showing substantial improvements across all domains.</p>
                </div>
                <div class="insight-card">
                    <h3><span class="takeaway-number">3</span> Reasoning: Helpful but Not Sufficient</h3>
                    <p>Effective thinking helps with hallucination mitigation in GPT-family models, but the effect is model-dependent (DeepSeek-Reasoner shows no improvement), and stronger reasoning can paradoxically increase hallucination risk by producing longer responses with more claims.</p>
                </div>
                <div class="insight-card">
                    <h3><span class="takeaway-number">4</span> Content Grounding Remains Challenging</h3>
                    <p>Content-grounding failures are far more common than reference-grounding failures, and while web search reduces reference errors, ensuring generated content is actually supported by cited sources remains difficult, especially for PDF-based research papers.</p>
                </div>
                <div class="insight-card">
                    <h3><span class="takeaway-number">5</span> Niche vs. Fabricated Knowledge</h3>
                    <p>Models struggle with niche facts (which have some training traces) but abstain on completely fabricated items, creating a "dangerous middle zone" where models feel answerable and fill in missing specifics with "most likely" details, leading to hallucinations.</p>
                </div>
                <div class="insight-card">
                    <h3><span class="takeaway-number">6</span> High Hallucination Rates Persist</h3>
                    <p>Even the strongest model configurations (Claude-Opus-4.5 and GPT-5.2 with web search) maintain substantial hallucination rates (~30%), underscoring the need for better uncertainty awareness and verification when handling niche or long-tail knowledge.</p>
                </div>
            </div>
        </div>

        <div class="info-section">
            <h2>About the Benchmark</h2>
            
            <div class="benchmark-overview" style="background: #f8f9fa; padding: 25px; border-radius: 10px; margin-bottom: 30px; border-left: 4px solid #007bff; max-width: 900px; margin-left: auto; margin-right: auto;">
                <p style="font-size: 1.1em; line-height: 1.8; margin: 0;">
                    HalluHard is a challenging multi-turn hallucination benchmark with <strong>950 seed questions</strong> across four domains: legal cases (250), research questions (250), medical guidelines (250), and coding (200). A <strong>user LLM</strong> generates engaging follow-up questions, and we measure <strong>3 rounds of conversation</strong> (initial question plus 2 follow-ups). For legal, research, and medical domains, we sample <strong>5 claims per response</strong> and judge claim-wise; for coding, we judge response-wise. Our verification pipeline extracts claims, retrieves evidence via web search, and fetches full-text sources (including PDF parsing) to verify whether cited material supports the generated content.
                </p>
            </div>
        </div>

        <div class="challenge-section">
            <h2>Why This Benchmark Is Hard</h2>
            <div class="challenge-grid">
                <div class="challenge-card">
                    <div class="challenge-icon">ðŸŽ¯</div>
                    <h3>Challenging Tasks</h3>
                    <p>The benchmark evaluates models on inherently difficult tasks that require precise knowledge, accurate citation, and careful content grounding across multiple domains.</p>
                </div>
                <div class="challenge-card">
                    <div class="challenge-icon">ðŸ”¬</div>
                    <h3>Rigorous Evaluation</h3>
                    <p>Our evaluation judge can read full PDFs to verify detailed content grounding, going beyond simple web search snippets. This enables more accurate and thorough verification of claims, making the benchmark significantly more challenging to pass.</p>
                </div>
            </div>
        </div>

        <div class="authors-section" style="max-width: 900px; margin: 40px auto; padding: 30px;">
            <h2>Authors</h2>
            <div class="authors" style="margin-top: 20px;">
                <p class="authors-list" style="font-size: 1.1em; line-height: 1.8;">
                    Dongyang Fan, Sebastien Delsad, Nicolas Flammarion, Maksym Andriushchenko
                </p>
            </div>
        </div>

        <div class="citation-section" style="max-width: 900px; margin: 40px auto; padding: 30px;">
            <h2>Citation</h2>
            <p style="margin-bottom: 15px;">If you use HalluHard in your research, please cite:</p>
            <div style="background: #f8f9fa; padding: 20px; border-radius: 8px; border-left: 4px solid #007bff;">
                <h3 style="margin-top: 0; margin-bottom: 15px; font-size: 1.1em;">BibTeX</h3>
                <pre style="background: #ffffff; padding: 15px; border-radius: 5px; overflow-x: auto; margin: 0; font-family: 'Courier New', monospace; font-size: 0.9em; line-height: 1.6;"><code>@inproceedings{fan2026halluhard,
  title={HalluHard: A Hard Multi-Turn Hallucination Benchmark},
  author={Fan, Dongyang and Delsad, Sebastien and Flammarion, Nicolas and Andriushchenko, Maksym},
  year={2026}
}</code></pre>
            </div>
        </div>

        <footer>
            <p>Last updated: <span id="last-updated">-</span></p>
            <p class="footer-links">
                <a href="https://github.com/fan1dy/halluhard" target="_blank">GitHub</a> |
                <a href="#" target="_blank">Paper</a> |
                <a href="#" target="_blank">Documentation</a>
            </p>
        </footer>
    </div>

    <script src="data/leaderboard-data.js"></script>
    <script src="script.js"></script>
</body>
</html>

